{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde83e1f",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbae61",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Load cvs files\n",
    "2. Merge files\n",
    "3. correct data types\n",
    "4. inputate NA\n",
    "\n",
    "Notebook 03\n",
    "5. Feature engeneering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4c29e",
   "metadata": {},
   "source": [
    "Problems\n",
    "date matching missing data for: only working for 2017\n",
    "    kiwo dates \n",
    "    holiday "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008437c",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2119937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d237e1",
   "metadata": {},
   "source": [
    "1. Load cvs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb431f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/bakery_prediction/0_DataPreparation/Raw/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m df_kiwo = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m/workspaces/bakery_prediction/0_DataPreparation/Raw/kiwo.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m df_daten = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m/workspaces/bakery_prediction/0_DataPreparation/Raw/umsatzdaten_gekuerzt.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_test = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/workspaces/bakery_prediction/0_DataPreparation/Raw/test.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m df_wetter = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m/workspaces/bakery_prediction/0_DataPreparation/Raw/wetter.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspaces/bakery_prediction/0_DataPreparation/Raw/test.csv'"
     ]
    }
   ],
   "source": [
    "# Load a CSV files\n",
    "df_kiwo = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/kiwo.csv')\n",
    "df_daten = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/umsatzdaten_gekuerzt.csv')\n",
    "df_test = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/test.csv')\n",
    "df_wetter = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/wetter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c865fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts to date and sets index\n",
    "df_kiwo['Datum'] = pd.to_datetime(df_kiwo['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "df_daten['Datum'] = pd.to_datetime(df_daten['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "df_wetter['Datum'] = pd.to_datetime(df_wetter['Datum'], format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d02f7",
   "metadata": {},
   "source": [
    "Creates id ang warengruppe for day with Umsatz 0 and for test dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd213d",
   "metadata": {},
   "source": [
    "2. Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367865f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes on a common column\n",
    "df_datenkiwo = pd.merge(df_daten, df_kiwo, on='Datum', how='left')\n",
    "\n",
    "df_merged = pd.merge(df_datenkiwo, df_wetter, on='Datum', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02de809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id      Datum  Warengruppe      Umsatz  KielerWoche  Bewoelkung  \\\n",
      "0  1307011 2013-07-01            1  148.828353          NaN         6.0   \n",
      "1  1307012 2013-07-01            2  535.856285          NaN         6.0   \n",
      "2  1307013 2013-07-01            3  201.198426          NaN         6.0   \n",
      "3  1307014 2013-07-01            4   65.890169          NaN         6.0   \n",
      "4  1307015 2013-07-01            5  317.475875          NaN         6.0   \n",
      "\n",
      "   Temperatur  Windgeschwindigkeit  Wettercode  \n",
      "0     17.8375                 15.0        20.0  \n",
      "1     17.8375                 15.0        20.0  \n",
      "2     17.8375                 15.0        20.0  \n",
      "3     17.8375                 15.0        20.0  \n",
      "4     17.8375                 15.0        20.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd65af",
   "metadata": {},
   "source": [
    "3. correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e071f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                          Datum   Warengruppe       Umsatz  \\\n",
      "count  1.141800e+04                          11418  11418.000000  9521.000000   \n",
      "mean   1.610074e+06  2016-07-17 15:15:36.416184832      3.091522   202.688329   \n",
      "min    1.307011e+06            2013-07-01 00:00:00      1.000000     0.000000   \n",
      "25%    1.501055e+06            2015-01-05 00:00:00      2.000000    93.908104   \n",
      "50%    1.607212e+06            2016-07-21 00:00:00      3.000000   158.097364   \n",
      "75%    1.801213e+06            2018-01-21 00:00:00      4.000000   278.341445   \n",
      "max    1.907315e+06            2019-07-31 00:00:00      6.000000  1879.461831   \n",
      "std    1.792840e+05                            NaN      1.490249   145.965932   \n",
      "\n",
      "       KielerWoche    Bewoelkung    Temperatur  Windgeschwindigkeit  \\\n",
      "count        268.0  11277.000000  11337.000000         11337.000000   \n",
      "mean           1.0      4.758624     11.965530            11.042604   \n",
      "min            1.0      0.000000     -8.475000             3.000000   \n",
      "25%            1.0      3.000000      6.250000             8.000000   \n",
      "50%            1.0      6.000000     11.475000            10.000000   \n",
      "75%            1.0      7.000000     17.762500            13.000000   \n",
      "max            1.0      8.000000     32.671428            35.000000   \n",
      "std            0.0      2.642548      7.179835             4.143428   \n",
      "\n",
      "        Wettercode  \n",
      "count  8708.000000  \n",
      "mean     36.117249  \n",
      "min       0.000000  \n",
      "25%      10.000000  \n",
      "50%      22.000000  \n",
      "75%      61.000000  \n",
      "max      95.000000  \n",
      "std      27.164733  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11418 entries, 0 to 11417\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   id                   11418 non-null  int64         \n",
      " 1   Datum                11418 non-null  datetime64[ns]\n",
      " 2   Warengruppe          11418 non-null  int64         \n",
      " 3   Umsatz               9521 non-null   float64       \n",
      " 4   KielerWoche          268 non-null    float64       \n",
      " 5   Bewoelkung           11277 non-null  float64       \n",
      " 6   Temperatur           11337 non-null  float64       \n",
      " 7   Windgeschwindigkeit  11337 non-null  float64       \n",
      " 8   Wettercode           8708 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(2)\n",
      "memory usage: 803.0 KB\n",
      "None\n",
      "id                         0\n",
      "Datum                      0\n",
      "Warengruppe                0\n",
      "Umsatz                  1897\n",
      "KielerWoche            11150\n",
      "Bewoelkung               141\n",
      "Temperatur                81\n",
      "Windgeschwindigkeit       81\n",
      "Wettercode              2710\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#descriptive statistics\n",
    "print(df_merged.describe())\n",
    "\n",
    "#data types and non-null counts\n",
    "print(df_merged.info())\n",
    "\n",
    "#missing values in each column\n",
    "print(df_merged.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7c86191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set warengruppe, bewoelkung, windgeschwindigkeit, wetter code and kieler woche as integer\n",
    "df_merged['Warengruppe'] = df_merged['Warengruppe'].astype('Int64')\n",
    "df_merged['Bewoelkung'] = df_merged['Bewoelkung'].astype('Int64')\n",
    "df_merged['Windgeschwindigkeit'] = df_merged['Windgeschwindigkeit'].astype('Int64')\n",
    "df_merged['Wettercode'] = df_merged['Wettercode'].astype('Int64')\n",
    "df_merged['KielerWoche'] = df_merged['KielerWoche'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d6f17",
   "metadata": {},
   "source": [
    "Save to csv// import from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c1659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save merged dataframe to a new CSV file\n",
    "df_merged.to_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33a969ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/merged_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b44f4",
   "metadata": {},
   "source": [
    "4. inputate NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30139aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputated = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b40472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                        0\n",
      "Datum                     0\n",
      "Warengruppe               0\n",
      "Umsatz                 1897\n",
      "KielerWoche               0\n",
      "Bewoelkung              141\n",
      "Temperatur               81\n",
      "Windgeschwindigkeit      81\n",
      "Wettercode                0\n",
      "Woche                     0\n",
      "Monat                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#missing values in each column\n",
    "print(df_inputated.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db25c7",
   "metadata": {},
   "source": [
    "Categorical Wettercode per week mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "669baa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive week and month for df_inputated\n",
    "df_inputated['Woche'] = pd.to_datetime(df_inputated['Datum']).dt.isocalendar().week\n",
    "df_inputated['Monat'] = pd.to_datetime(df_inputated['Datum']).dt.month\n",
    "\n",
    "# precompute weekly and monthly modes (ignore NaNs when computing mode)\n",
    "weekly_mode_map = df_inputated.groupby('Woche')['Wettercode'].agg(\n",
    "    lambda s: s.dropna().mode().iloc[0] if not s.dropna().mode().empty else pd.NA\n",
    ").to_dict()\n",
    "\n",
    "monthly_mode_map = df_inputated.groupby('Monat')['Wettercode'].agg(\n",
    "    lambda s: s.dropna().mode().iloc[0] if not s.dropna().mode().empty else pd.NA\n",
    ").to_dict()\n",
    "\n",
    "# fill missing Wettercode: use weekly mode, if not available fallback to monthly mode\n",
    "def fill_wettercode_row(row):\n",
    "    if pd.isna(row['Wettercode']):\n",
    "        w_mode = weekly_mode_map.get(row['Woche'], pd.NA)\n",
    "        if not pd.isna(w_mode):\n",
    "            return w_mode\n",
    "        return monthly_mode_map.get(row['Monat'], pd.NA)\n",
    "    return row['Wettercode']\n",
    "\n",
    "df_inputated['Wettercode'] = df_inputated.apply(fill_wettercode_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67940ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTES: KielerWoche\n",
      "<NA>    11150\n",
      "1         268\n",
      "Name: count, dtype: Int64\n",
      "DEPOIS: KielerWoche\n",
      "<NA>    11150\n",
      "1         268\n",
      "Name: count, dtype: Int64\n",
      "Flips: 0\n",
      "Empty DataFrame\n",
      "Columns: [Datum, KW_before]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['KielerWoche']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Compare antes vs depois\n",
    "print(\"ANTES:\", df_merged['KielerWoche'].value_counts(dropna=False))\n",
    "print(\"DEPOIS:\", df_inputated['KielerWoche'].value_counts(dropna=False))\n",
    "\n",
    "# 2) Quais linhas viraram 0?\n",
    "flip = (df_merged['KielerWoche'] == 1) & (df_inputated['KielerWoche'] == 0)\n",
    "print(\"Flips:\", flip.sum())\n",
    "print(df_merged.loc[flip, ['Datum']].assign(KW_before=1).head())\n",
    "\n",
    "# 3) Veja se há múltiplas colunas de KielerWoche após os merges\n",
    "[k for k in df_merged.columns if 'KielerWoche' in k]\n",
    "[k for k in df_inputated.columns if 'KielerWoche' in k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25ed30",
   "metadata": {},
   "source": [
    "set not kiwo to 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc0504ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19963/3859340180.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_inputated['KielerWoche'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#fix kieler woche missing values by filling with 0\n",
    "df_inputated['KielerWoche'].fillna(0, inplace=True)\n",
    "\n",
    "#set 'KielerWoche' as integer (nullable int64 to allow current NaNs)\n",
    "df_inputated['KielerWoche'] = df_inputated['KielerWoche'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fae48",
   "metadata": {},
   "source": [
    "missing Bewoelkung, Temperatur and/or Windgeschwindigkeit\n",
    "Inputated with mean of day after and before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9fe93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Bewoelkung  Temperatur  Windgeschwindigkeit\n",
      "6458         <NA>         NaN                 <NA>\n",
      "6459         <NA>         NaN                 <NA>\n",
      "6460         <NA>         NaN                 <NA>\n",
      "6461         <NA>         NaN                 <NA>\n",
      "6462         <NA>         NaN                 <NA>\n",
      "...           ...         ...                  ...\n",
      "10823        <NA>         NaN                 <NA>\n",
      "10824        <NA>         NaN                 <NA>\n",
      "10825        <NA>         NaN                 <NA>\n",
      "10826        <NA>         NaN                 <NA>\n",
      "10827        <NA>         NaN                 <NA>\n",
      "\n",
      "[141 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#what days are missing Bewoelkung, Temperatur and/or     Windgeschwindigkeit\n",
    "missing_weather = df_inputated[df_inputated[['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']].isnull().any(axis=1)]\n",
    "print(missing_weather[[ 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e8a21",
   "metadata": {},
   "source": [
    "fill Bewoelkung, Temperatur, Windgeschwindigkeit to mean of day before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a009e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing weather data with the mean of day before and after\n",
    "df_inputated['Bewoelkung'] = df_inputated['Bewoelkung'].interpolate()\n",
    "df_inputated['Temperatur'] = df_inputated['Temperatur'].interpolate()\n",
    "df_inputated['Windgeschwindigkeit'] = df_inputated['Windgeschwindigkeit'].interpolate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a0c7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set warengruppe, bewoelkung, windgeschwindigkeit, wetter code and kieler woche as integer\n",
    "df_inputated['Bewoelkung'] = df_inputated['Bewoelkung'].astype('int64')\n",
    "df_inputated['Windgeschwindigkeit'] = df_inputated['Windgeschwindigkeit'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32138d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bewoelkung before imputation: 4.945510835913312\n",
      "Mean Bewoelkung after imputation: 4.887049083382614\n",
      "Mean Temperatur before imputation: 12.10357675761194\n",
      "Mean Temperatur after imputation: 11.987884596514277\n",
      "Mean Windgeschwindigkeit before imputation: 11.042603863455941\n",
      "Mean Windgeschwindigkeit after imputation: 11.038623226484498\n"
     ]
    }
   ],
   "source": [
    "# median values before and after imputation from 2016-12-11 to 2017-11-08\n",
    "df_merged_ = df_merged[(df_merged['Datum'] >= '2016-12-11') & (df_merged['Datum'] <= '2017-11-08')]\n",
    "df_inputated_ = df_inputated[(df_inputated['Datum'] >= '2016-12-11') & (df_inputated['Datum'] <= '2017-11-08')]\n",
    "\n",
    "print(\"Mean Bewoelkung before imputation:\", df_merged_['Bewoelkung'].mean())\n",
    "print(\"Mean Bewoelkung after imputation:\", df_inputated_['Bewoelkung'].mean())\n",
    "print(\"Mean Temperatur before imputation:\", df_merged_['Temperatur'].mean())\n",
    "print(\"Mean Temperatur after imputation:\", df_inputated['Temperatur'].mean())\n",
    "print(\"Mean Windgeschwindigkeit before imputation:\", df_merged['Windgeschwindigkeit'].mean())\n",
    "print(\"Mean Windgeschwindigkeit after imputation:\", df_inputated['Windgeschwindigkeit'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d6d0a",
   "metadata": {},
   "source": [
    "Discrepancies of Bewoelkung, Temperatur and/or     Windgeschwindigkeit for the same day across WarenGruppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a87d7c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in weather data for the same date:\n",
      "          Datum  Bewoelkung  Temperatur  Windgeschwindigkeit\n",
      "1258 2016-12-11           1           6                    6\n",
      "1555 2017-10-04           2           5                    1\n",
      "1556 2017-10-05           2           5                    1\n",
      "1583 2017-11-01           2           1                    1\n",
      "1588 2017-11-06           2           1                    1\n",
      "1894 2018-09-08           1           5                    1\n",
      "1895 2018-09-09           1           5                    1\n",
      "1901 2018-09-15           1           5                    2\n",
      "1902 2018-09-16           1           5                    2\n",
      "1903 2018-09-17           1           5                    2\n",
      "1904 2018-09-18           1           5                    2\n",
      "1905 2018-09-19           1           5                    2\n",
      "1906 2018-09-20           1           5                    2\n",
      "1929 2018-10-13           1           5                    1\n",
      "1930 2018-10-14           1           5                    1\n",
      "1936 2018-10-20           1           5                    4\n",
      "1937 2018-10-21           1           5                    4\n",
      "2102 2019-04-04           5           5                    1\n"
     ]
    }
   ],
   "source": [
    "# check if there are discrepancies for the same date for the columns 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit'\n",
    "#for 'Warengruppe' 6 the temperature is different for the same date as the other 'Warengruppe'\n",
    "discrepancies = df_inputated.groupby('Datum').agg({\n",
    "    'Bewoelkung': pd.Series.nunique,\n",
    "    'Temperatur': pd.Series.nunique,\n",
    "    'Windgeschwindigkeit': pd.Series.nunique\n",
    "}).reset_index() \n",
    "discrepancies = discrepancies[(discrepancies['Bewoelkung'] > 1) | (discrepancies['Temperatur'] > 1) | (discrepancies['Windgeschwindigkeit'] > 1)]\n",
    "print(\"Discrepancies in weather data for the same date:\")\n",
    "print(discrepancies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438c599",
   "metadata": {},
   "source": [
    "uses value of WarenGruppe 1 to all groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e83db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']\n",
    "\n",
    "for date in discrepancies['Datum']:\n",
    "    weather_values = df_inputated.loc[df_inputated['Datum'] == date, ['Warengruppe'] + cols]\n",
    "    reference_values = weather_values.loc[weather_values['Warengruppe'] == 1, cols].iloc[0]\n",
    "    # >>> use .values para evitar alinhamento por rótulo <<<\n",
    "    df_inputated.loc[df_inputated['Datum'] == date, cols] = reference_values.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d6041",
   "metadata": {},
   "source": [
    "Save to csv// import from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6332ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save inputated dataframe to a new CSV file\n",
    "\n",
    "df_inputated.to_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/inputated_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputated = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/inputated_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
