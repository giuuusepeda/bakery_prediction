{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde83e1f",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbae61",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Load cvs files\n",
    "2. Merge files\n",
    "3. correct data types\n",
    "4. inputate NA\n",
    "5. Feature engeneering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4c29e",
   "metadata": {},
   "source": [
    "Problems\n",
    "date matching missing data for: only working for 2017\n",
    "    kiwo dates \n",
    "    holiday "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008437c",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2119937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d237e1",
   "metadata": {},
   "source": [
    "1. Load cvs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bb431f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV files\n",
    "df_kiwo = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/kiwo.csv')\n",
    "df_daten = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/umsatzdaten_gekuerzt.csv')\n",
    "df_wetter = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/wetter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c865fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts to date and sets index\n",
    "df_kiwo['Datum'] = pd.to_datetime(df_kiwo['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "df_daten['Datum'] = pd.to_datetime(df_daten['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "df_wetter['Datum'] = pd.to_datetime(df_wetter['Datum'], format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d02f7",
   "metadata": {},
   "source": [
    "Creates id ang warengruppe for day with Umsatz 0 and for test dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ab070",
   "metadata": {},
   "outputs": [],
   "source": [
    "warengruppe6_dates = pd.to_datetime([\n",
    "    '10-24' '10-25' '10-26' '10-27' '10-29' '10-30' '10-31' '11-01' '11-02' '11-03' '11-04' '11-05' '11-06' '11-07' '11-08' '11-09' '11-10' '11-11' '11-12' '11-13' '11-14' '11-15' '11-16' '11-17' '11-18' '11-19' '11-20' '11-21' '11-22' '11-23' '11-24' '11-25' '11-26' '11-27' '11-28' '11-29' '11-30' '12-01' '12-02' '12-03' '12-04' '12-05' '12-06' '12-07' '12-08' '12-09' '12-10' '12-11' '12-12' '12-13' '12-14' '12-15' '12-16' '12-17''12-18' '12-19' '12-20' '12-21' '12-22' '12-23' '12-24' '12-27' '12-29' '12-30' '01-02' '10-28' '12-28' '01-03' '01-04' '01-05' '01-06' '12-31'])\n",
    "\n",
    "dates_umsatz_null = pd.to_datetime([\n",
    "    \"2013-12-25\", \"2013-12-26\", \"2014-01-01\",\n",
    "    \"2014-04-18\", \"2014-05-01\", \"2014-05-03\",\n",
    "    \"2014-05-04\", \"2014-08-17\", \"2014-12-25\",\n",
    "    \"2014-12-26\", \"2015-01-01\", \"2015-04-03\",\n",
    "    \"2015-05-01\", \"2015-12-25\", \"2015-12-26\",\n",
    "    \"2016-01-01\", \"2016-03-24\", \"2016-03-25\",\n",
    "    \"2016-07-07\", \"2016-07-18\", \"2016-08-14\",\n",
    "    \"2016-08-15\", \"2016-12-17\", \"2016-12-25\",\n",
    "    \"2016-12-26\", \"2017-01-01\", \"2017-04-14\",\n",
    "    \"2017-05-01\", \"2017-07-04\", \"2017-10-23\",\n",
    "    \"2017-10-31\", \"2017-12-25\", \"2017-12-26\",\n",
    "    \"2018-01-01\", \"2018-03-30\", \"2018-05-01\",\n",
    "    \"2018-05-21\"\n",
    "])\n",
    "\n",
    "def prepare_dataset(df_daten, warengruppe6_dates=None, dates_umsatz_null=None):\n",
    "    \"\"\"\n",
    "    Prepara o dataset para modelagem:\n",
    "    - Expande todas as datas em Warengruppe 1..5 ou 1..6 (se estiver em warengruppe6_dates)\n",
    "    - Replica features diárias para cada Warengruppe\n",
    "    - Junta Umsatz original (quando existir)\n",
    "    - Coloca Umsatz = 0 para datas em dates_umsatz_null ou sem venda\n",
    "    - Cria coluna id = YYMMDD + Warengruppe\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df_inputated.copy()\n",
    "    \n",
    "    # Garantir tipo datetime\n",
    "    df[\"Datum\"] = pd.to_datetime(df[\"Datum\"])\n",
    "    \n",
    "    # Normalizar listas de datas (podem vir como lista de strings)\n",
    "    if warengruppe6_dates is None:\n",
    "        warengruppe6_dates = pd.to_datetime([])\n",
    "    else:\n",
    "        warengruppe6_dates = pd.to_datetime(warengruppe6_dates)\n",
    "    \n",
    "    if dates_umsatz_null is None:\n",
    "        dates_umsatz_null = pd.to_datetime([])\n",
    "    else:\n",
    "        dates_umsatz_null = pd.to_datetime(dates_umsatz_null)\n",
    "    \n",
    "    # --- 1) Features por data (clima, KielerWoche etc.) ---\n",
    "    # Vamos pegar todas as colunas exceto Warengruppe, Umsatz e id\n",
    "    cols_date_level = [c for c in df.columns if c not in [\"Warengruppe\", \"Umsatz\", \"id\"]]\n",
    "    \n",
    "    # Um registro por data (assumindo que clima, feriado, etc. é igual no dia todo)\n",
    "    date_features = df[cols_date_level].drop_duplicates(subset=[\"Datum\"])\n",
    "    \n",
    "    # Lista de datas únicas\n",
    "    unique_dates = date_features[\"Datum\"].drop_duplicates().sort_values()\n",
    "    \n",
    "    # --- 2) Criar grade completa Datum x Warengruppe ---\n",
    "    rows = []\n",
    "    for date in unique_dates:\n",
    "        if date in warengruppe6_dates:\n",
    "            groups = range(1, 7)   # 1..6\n",
    "        else:\n",
    "            groups = range(1, 6)   # 1..5\n",
    "        \n",
    "        for g in groups:\n",
    "            rows.append({\"Datum\": date, \"Warengruppe\": g})\n",
    "    \n",
    "    full_grid = pd.DataFrame(rows)\n",
    "    \n",
    "    # --- 3) Juntar features diárias na grade ---\n",
    "    df_expanded = full_grid.merge(date_features, on=\"Datum\", how=\"left\")\n",
    "    \n",
    "    # --- 4) Juntar Umsatz original (por Datum + Warengruppe) ---\n",
    "    if \"Warengruppe\" in df.columns:\n",
    "        umsatz_source = df[[\"Datum\", \"Warengruppe\", \"Umsatz\"]].copy()\n",
    "        df_expanded = df_expanded.merge(\n",
    "            umsatz_source,\n",
    "            on=[\"Datum\", \"Warengruppe\"],\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_orig\")\n",
    "        )\n",
    "    else:\n",
    "        # se não existir Warengruppe no original, só cria a coluna\n",
    "        df_expanded[\"Umsatz\"] = pd.NA\n",
    "    \n",
    "    # --- 5) Tratar Umsatz = 0 para datas sem venda ---\n",
    "    # Para datas explicitamente sem venda\n",
    "    df_expanded.loc[df_expanded[\"Datum\"].isin(dates_umsatz_null), \"Umsatz\"] = 0\n",
    "    \n",
    "    # Qualquer NaN restante também vira 0\n",
    "    df_expanded[\"Umsatz\"] = df_expanded[\"Umsatz\"].fillna(0)\n",
    "    \n",
    "    # --- 6) Criar coluna id ---\n",
    "    df_expanded[\"id\"] = (\n",
    "        df_expanded[\"Datum\"].dt.strftime(\"%y%m%d\") +\n",
    "        df_expanded[\"Warengruppe\"].astype(int).astype(str)\n",
    "    )\n",
    "    \n",
    "    # --- 7) Ordenar e retornar ---\n",
    "    df_expanded = df_expanded.sort_values([\"Datum\", \"Warengruppe\"]).reset_index(drop=True)\n",
    "    \n",
    "    return df_expanded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd213d",
   "metadata": {},
   "source": [
    "2. Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "367865f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes on a common column\n",
    "df_kiwowetter = pd.merge(df_daten, df_kiwo, on='Datum', how='outer')\n",
    "\n",
    "df_merged = pd.merge(df_kiwowetter, df_wetter, on='Datum', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a02de809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      Datum  Warengruppe  Umsatz  KielerWoche  Bewoelkung  Temperatur  \\\n",
      "0 NaN 2012-01-01          NaN     NaN          NaN         8.0      9.8250   \n",
      "1 NaN 2012-01-02          NaN     NaN          NaN         7.0      7.4375   \n",
      "2 NaN 2012-01-03          NaN     NaN          NaN         8.0      5.5375   \n",
      "3 NaN 2012-01-04          NaN     NaN          NaN         4.0      5.6875   \n",
      "4 NaN 2012-01-05          NaN     NaN          NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode  \n",
      "0                 14.0        58.0  \n",
      "1                 12.0         NaN  \n",
      "2                 18.0        63.0  \n",
      "3                 19.0        80.0  \n",
      "4                 23.0        80.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d3d4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset based on datum from 01.07.2013 to 31.07.2019.\n",
    "df_merged = df_merged[(df_merged['Datum'] >= '2013-07-01') & (df_merged['Datum'] <= '2019-07-31')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd65af",
   "metadata": {},
   "source": [
    "3. correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6e071f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                          Datum  Warengruppe       Umsatz  \\\n",
      "count  9.334000e+03                           9724  9334.000000  9334.000000   \n",
      "mean   1.559311e+06  2016-02-23 14:29:16.314273792     3.088172   206.749044   \n",
      "min    1.307011e+06            2013-07-01 00:00:00     1.000000     7.051201   \n",
      "25%    1.410123e+06            2014-10-29 00:00:00     2.000000    96.897441   \n",
      "50%    1.601102e+06            2016-02-14 12:00:00     3.000000   161.900831   \n",
      "75%    1.704223e+06            2017-06-15 00:00:00     4.000000   280.644663   \n",
      "max    1.807315e+06            2019-07-31 00:00:00     6.000000  1879.461831   \n",
      "std    1.512503e+05                            NaN     1.489002   144.545189   \n",
      "\n",
      "       KielerWoche  Bewoelkung   Temperatur  Windgeschwindigkeit   Wettercode  \n",
      "count        232.0  9653.00000  9708.000000          9708.000000  7337.000000  \n",
      "mean           1.0     4.72796    12.021734            10.992274    36.716369  \n",
      "min            1.0     0.00000    -8.475000             3.000000     0.000000  \n",
      "25%            1.0     3.00000     6.250000             8.000000    10.000000  \n",
      "50%            1.0     6.00000    11.625000            10.000000    28.000000  \n",
      "75%            1.0     7.00000    17.937500            13.000000    61.000000  \n",
      "max            1.0     8.00000    32.671428            35.000000    95.000000  \n",
      "std            0.0     2.64547     7.221516             4.134352    27.117069  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9724 entries, 394 to 10117\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   id                   9334 non-null   float64       \n",
      " 1   Datum                9724 non-null   datetime64[ns]\n",
      " 2   Warengruppe          9334 non-null   float64       \n",
      " 3   Umsatz               9334 non-null   float64       \n",
      " 4   KielerWoche          232 non-null    float64       \n",
      " 5   Bewoelkung           9653 non-null   float64       \n",
      " 6   Temperatur           9708 non-null   float64       \n",
      " 7   Windgeschwindigkeit  9708 non-null   float64       \n",
      " 8   Wettercode           7337 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(8)\n",
      "memory usage: 759.7 KB\n",
      "None\n",
      "id                      390\n",
      "Datum                     0\n",
      "Warengruppe             390\n",
      "Umsatz                  390\n",
      "KielerWoche            9492\n",
      "Bewoelkung               71\n",
      "Temperatur               16\n",
      "Windgeschwindigkeit      16\n",
      "Wettercode             2387\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#descriptive statistics\n",
    "print(df_merged.describe())\n",
    "\n",
    "#data types and non-null counts\n",
    "print(df_merged.info())\n",
    "\n",
    "#missing values in each column\n",
    "print(df_merged.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7c86191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set warengruppe, bewoelkung, windgeschwindigkeit, wetter code and kieler woche as integer\n",
    "df_merged['Warengruppe'] = df_merged['Warengruppe'].astype('Int64')\n",
    "df_merged['Bewoelkung'] = df_merged['Bewoelkung'].astype('Int64')\n",
    "df_merged['Windgeschwindigkeit'] = df_merged['Windgeschwindigkeit'].astype('Int64')\n",
    "df_merged['Wettercode'] = df_merged['Wettercode'].astype('Int64')\n",
    "df_merged['KielerWoche'] = df_merged['KielerWoche'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d6f17",
   "metadata": {},
   "source": [
    "Save to csv// import from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13c1659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save merged dataframe to a new CSV file\n",
    "df_merged.to_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33a969ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/merged_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b44f4",
   "metadata": {},
   "source": [
    "4. inputate NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "30139aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputated = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "26b40472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                       38\n",
      "Datum                     0\n",
      "Warengruppe              38\n",
      "Umsatz                 1798\n",
      "KielerWoche            1760\n",
      "Bewoelkung             1760\n",
      "Temperatur             1760\n",
      "Windgeschwindigkeit    1760\n",
      "Wettercode             4092\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#missing values in each column\n",
    "print(df_inputated.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f4e3f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN dentro da máscara: 352\n",
      "NaN fora da máscara: 38\n"
     ]
    }
   ],
   "source": [
    "# Quantos NaN em Warengruppe dentro da máscara?\n",
    "mask = (df_merged['Datum'] >= '2018-08-01') & (df_merged['Datum'] <= '2019-07-31')\n",
    "\n",
    "print(\"NaN dentro da máscara:\", df_merged.loc[mask, \"Warengruppe\"].isna().sum())\n",
    "print(\"NaN fora da máscara:\", df_merged.loc[~mask, \"Warengruppe\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db25c7",
   "metadata": {},
   "source": [
    "Categorical Wettercode per week mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669baa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# derive week and month for df_inputated\n",
    "df_inputated['Woche'] = pd.to_datetime(df_inputated['Datum']).dt.isocalendar().week\n",
    "df_inputated['Monat'] = pd.to_datetime(df_inputated['Datum']).dt.month\n",
    "\n",
    "# precompute weekly and monthly modes (ignore NaNs when computing mode)\n",
    "weekly_mode_map = df_inputated.groupby('Woche')['Wettercode'].agg(\n",
    "    lambda s: s.dropna().mode().iloc[0] if not s.dropna().mode().empty else pd.NA\n",
    ").to_dict()\n",
    "\n",
    "monthly_mode_map = df_inputated.groupby('Monat')['Wettercode'].agg(\n",
    "    lambda s: s.dropna().mode().iloc[0] if not s.dropna().mode().empty else pd.NA\n",
    ").to_dict()\n",
    "\n",
    "# fill missing Wettercode: use weekly mode, if not available fallback to monthly mode\n",
    "def fill_wettercode_row(row):\n",
    "    if pd.isna(row['Wettercode']):\n",
    "        w_mode = weekly_mode_map.get(row['Woche'], pd.NA)\n",
    "        if not pd.isna(w_mode):\n",
    "            return w_mode\n",
    "        return monthly_mode_map.get(row['Monat'], pd.NA)\n",
    "    return row['Wettercode']\n",
    "\n",
    "df_inputated['Wettercode'] = df_inputated.apply(fill_wettercode_row, axis=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67940ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# 1) Compare antes vs depois\n",
    "print(\"ANTES:\", df_merged['KielerWoche'].value_counts(dropna=False))\n",
    "print(\"DEPOIS:\", df_inputated['KielerWoche'].value_counts(dropna=False))\n",
    "\n",
    "# 2) Quais linhas viraram 0?\n",
    "flip = (df_merged['KielerWoche'] == 1) & (df_inputated['KielerWoche'] == 0)\n",
    "print(\"Flips:\", flip.sum())\n",
    "print(df_merged.loc[flip, ['Datum']].assign(KW_before=1).head())\n",
    "\n",
    "# 3) Veja se há múltiplas colunas de KielerWoche após os merges\n",
    "[k for k in df_merged.columns if 'KielerWoche' in k]\n",
    "[k for k in df_inputated.columns if 'KielerWoche' in k]'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25ed30",
   "metadata": {},
   "source": [
    "set not kiwo to 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dc0504ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3163/3859340180.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_inputated['KielerWoche'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#fix kieler woche missing values by filling with 0\n",
    "df_inputated['KielerWoche'].fillna(0, inplace=True)\n",
    "\n",
    "#set 'KielerWoche' as integer (nullable int64 to allow current NaNs)\n",
    "df_inputated['KielerWoche'] = df_inputated['KielerWoche'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fae48",
   "metadata": {},
   "source": [
    "missing Bewoelkung, Temperatur and/or Windgeschwindigkeit\n",
    "Inputated with mean of day after and before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a9fe93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Bewoelkung  Temperatur  Windgeschwindigkeit\n",
      "6371         NaN         NaN                  NaN\n",
      "6372         NaN         NaN                  NaN\n",
      "6373         NaN         NaN                  NaN\n",
      "6374         NaN         NaN                  NaN\n",
      "6375         NaN         NaN                  NaN\n",
      "...          ...         ...                  ...\n",
      "8019         NaN       8.625                  9.0\n",
      "8020         NaN       8.625                  9.0\n",
      "8021         NaN       8.625                  9.0\n",
      "8022         NaN       8.625                  9.0\n",
      "8023         NaN       8.625                  9.0\n",
      "\n",
      "[71 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#what days are missing Bewoelkung, Temperatur and/or     Windgeschwindigkeit\n",
    "missing_weather = df_inputated[df_inputated[['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']].isnull().any(axis=1)]\n",
    "print(missing_weather[[ 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e8a21",
   "metadata": {},
   "source": [
    "fill Bewoelkung, Temperatur, Windgeschwindigkeit to mean of day before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a009e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing weather data with the mean of day before and after\n",
    "df_inputated['Bewoelkung'] = df_inputated['Bewoelkung'].interpolate()\n",
    "df_inputated['Temperatur'] = df_inputated['Temperatur'].interpolate()\n",
    "df_inputated['Windgeschwindigkeit'] = df_inputated['Windgeschwindigkeit'].interpolate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8a0c7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set warengruppe, bewoelkung, windgeschwindigkeit, wetter code and kieler woche as integer\n",
    "df_inputated['Bewoelkung'] = df_inputated['Bewoelkung'].astype('int64')\n",
    "df_inputated['Windgeschwindigkeit'] = df_inputated['Windgeschwindigkeit'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "32138d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bewoelkung before imputation: 4.922250316055626\n",
      "Mean Bewoelkung after imputation: 4.868723532970357\n",
      "Mean Temperatur before imputation: 12.174979272449603\n",
      "Mean Temperatur after imputation: 12.020863154668861\n",
      "Mean Windgeschwindigkeit before imputation: 10.992274412855377\n",
      "Mean Windgeschwindigkeit after imputation: 10.99156725627314\n"
     ]
    }
   ],
   "source": [
    "# median values before and after imputation from 2016-12-11 to 2017-11-08\n",
    "df_merged_ = df_merged[(df_merged['Datum'] >= '2016-12-11') & (df_merged['Datum'] <= '2017-11-08')]\n",
    "df_inputated_ = df_inputated[(df_inputated['Datum'] >= '2016-12-11') & (df_inputated['Datum'] <= '2017-11-08')]\n",
    "\n",
    "print(\"Mean Bewoelkung before imputation:\", df_merged_['Bewoelkung'].mean())\n",
    "print(\"Mean Bewoelkung after imputation:\", df_inputated_['Bewoelkung'].mean())\n",
    "print(\"Mean Temperatur before imputation:\", df_merged_['Temperatur'].mean())\n",
    "print(\"Mean Temperatur after imputation:\", df_inputated['Temperatur'].mean())\n",
    "print(\"Mean Windgeschwindigkeit before imputation:\", df_merged['Windgeschwindigkeit'].mean())\n",
    "print(\"Mean Windgeschwindigkeit after imputation:\", df_inputated['Windgeschwindigkeit'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d6d0a",
   "metadata": {},
   "source": [
    "Discrepancies of Bewoelkung, Temperatur and/or     Windgeschwindigkeit for the same day across WarenGruppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a87d7c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in weather data for the same date:\n",
      "           Datum  Bewoelkung  Temperatur  Windgeschwindigkeit\n",
      "1259  2016-12-11           1           6                    6\n",
      "1556  2017-10-04           2           5                    1\n",
      "1557  2017-10-05           2           5                    1\n",
      "1587  2017-11-04           2           1                    1\n",
      "1589  2017-11-06           2           1                    1\n"
     ]
    }
   ],
   "source": [
    "# check if there are discrepancies for the same date for the columns 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit'\n",
    "#for 'Warengruppe' 6 the temperature is different for the same date as the other 'Warengruppe'\n",
    "discrepancies = df_inputated.groupby('Datum').agg({\n",
    "    'Bewoelkung': pd.Series.nunique,\n",
    "    'Temperatur': pd.Series.nunique,\n",
    "    'Windgeschwindigkeit': pd.Series.nunique\n",
    "}).reset_index() \n",
    "discrepancies = discrepancies[(discrepancies['Bewoelkung'] > 1) | (discrepancies['Temperatur'] > 1) | (discrepancies['Windgeschwindigkeit'] > 1)]\n",
    "print(\"Discrepancies in weather data for the same date:\")\n",
    "print(discrepancies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438c599",
   "metadata": {},
   "source": [
    "uses value of WarenGruppe 1 to all groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e83db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']\n",
    "\n",
    "for date in discrepancies['Datum']:\n",
    "    weather_values = df_inputated.loc[df_inputated['Datum'] == date, ['Warengruppe'] + cols]\n",
    "    reference_values = weather_values.loc[weather_values['Warengruppe'] == 1, cols].iloc[0]\n",
    "    # >>> use .values para evitar alinhamento por rótulo <<<\n",
    "    df_inputated.loc[df_inputated['Datum'] == date, cols] = reference_values.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da3ff98",
   "metadata": {},
   "source": [
    "For from 01.08.2018 to 31.07.2019 set id and Warengroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0fc988a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warengruppe 6 is available on the following month-day combinations:\n",
      "['10-24' '10-25' '10-26' '10-27' '10-29' '10-30' '10-31' '11-01' '11-02'\n",
      " '11-03' '11-04' '11-05' '11-06' '11-07' '11-08' '11-09' '11-10' '11-11'\n",
      " '11-12' '11-13' '11-14' '11-15' '11-16' '11-17' '11-18' '11-19' '11-20'\n",
      " '11-21' '11-22' '11-23' '11-24' '11-25' '11-26' '11-27' '11-28' '11-29'\n",
      " '11-30' '12-01' '12-02' '12-03' '12-04' '12-05' '12-06' '12-07' '12-08'\n",
      " '12-09' '12-10' '12-11' '12-12' '12-13' '12-14' '12-15' '12-16' '12-17'\n",
      " '12-18' '12-19' '12-20' '12-21' '12-22' '12-23' '12-24' '12-27' '12-29'\n",
      " '12-30' '01-02' '10-28' '12-28' '01-03' '01-04' '01-05' '01-06' '12-31']\n"
     ]
    }
   ],
   "source": [
    "#check for what month and days (no year) warengruppe 6 is avalable every year\n",
    "mask = df_inputated['Warengruppe'] == 6\n",
    "# ensure the 'Datum' values are datetime-like before using .dt (do not overwrite original column)\n",
    "date_series = pd.to_datetime(df_inputated.loc[mask, 'Datum'], errors='coerce')\n",
    "warengruppe6_dates = date_series.dt.strftime('%m-%d').dropna().unique()\n",
    "print(\"Warengruppe 6 is available on the following month-day combinations:\")\n",
    "print(warengruppe6_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "93c23caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Warengruppe</th>\n",
       "      <th>Umsatz</th>\n",
       "      <th>KielerWoche</th>\n",
       "      <th>Bewoelkung</th>\n",
       "      <th>Temperatur</th>\n",
       "      <th>Windgeschwindigkeit</th>\n",
       "      <th>Wettercode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1307011.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148.828353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1307012.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>535.856285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1307013.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.198426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307014.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.890169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307015.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>317.475875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      Datum  Warengruppe      Umsatz  KielerWoche  Bewoelkung  \\\n",
       "0  1307011.0 2013-07-01          1.0  148.828353          0.0         6.0   \n",
       "1  1307012.0 2013-07-01          2.0  535.856285          0.0         6.0   \n",
       "2  1307013.0 2013-07-01          3.0  201.198426          0.0         6.0   \n",
       "3  1307014.0 2013-07-01          4.0   65.890169          0.0         6.0   \n",
       "4  1307015.0 2013-07-01          5.0  317.475875          0.0         6.0   \n",
       "\n",
       "   Temperatur  Windgeschwindigkeit  Wettercode  \n",
       "0     17.8375                 15.0        20.0  \n",
       "1     17.8375                 15.0        20.0  \n",
       "2     17.8375                 15.0        20.0  \n",
       "3     17.8375                 15.0        20.0  \n",
       "4     17.8375                 15.0        20.0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# máscara fornecida\n",
    "mask = (df_inputated['Datum'] >= '2018-08-01') & (df_inputated['Datum'] <= '2019-07-31')\n",
    "\n",
    "# lista das datas que devem ter 6 grupos\n",
    "\n",
    "# garante que Datum é datetime\n",
    "df_inputated[\"Datum\"] = pd.to_datetime(df_inputated[\"Datum\"])\n",
    "\n",
    "# separa o bloco que será expandido\n",
    "df_to_expand = df_inputated.loc[mask, [\"Datum\"]].drop_duplicates()\n",
    "\n",
    "def expand_groups(row):\n",
    "    date = row[\"Datum\"]\n",
    "    if date in warengruppe6_dates:\n",
    "        grupos = range(1, 7)   # 1..6\n",
    "    else:\n",
    "        grupos = range(1, 6)   # 1..5\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        \"Datum\": [date] * len(grupos),\n",
    "        \"Warengruppe\": grupos\n",
    "    })\n",
    "\n",
    "# gera linhas expandidas\n",
    "expanded_rows = pd.concat(df_to_expand.apply(expand_groups, axis=1).to_list(), ignore_index=True)\n",
    "\n",
    "# cria ID (YYMMDD + warengruppe)\n",
    "expanded_rows[\"YYMMDD\"] = expanded_rows[\"Datum\"].dt.strftime(\"%y%m%d\")\n",
    "expanded_rows[\"id\"] = expanded_rows[\"YYMMDD\"] + expanded_rows[\"Warengruppe\"].astype(str)\n",
    "expanded_rows.drop(columns=[\"YYMMDD\"], inplace=True)\n",
    "\n",
    "# remove as linhas originais que estavam dentro da máscara\n",
    "df_inputated = df_inputated.loc[~mask]\n",
    "\n",
    "# adiciona as novas linhas expandidas\n",
    "df_inputated = pd.concat([df_inputated, expanded_rows], ignore_index=True)\n",
    "\n",
    "# reordena se quiser\n",
    "df_inputated = df_inputated.sort_values(by=[\"Datum\", \"Warengruppe\"], ignore_index=True)\n",
    "\n",
    "df_inputated.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d13dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo da sua lista\n",
    "dates_umsatz_null = pd.to_datetime([\n",
    "    \"2013-12-25\", \"2013-12-26\", \"2014-01-01\",\n",
    "    \"2014-04-18\", \"2014-05-01\", \"2014-05-03\",\n",
    "    \"2014-05-04\", \"2014-08-17\", \"2014-12-25\",\n",
    "    \"2014-12-26\", \"2015-01-01\", \"2015-04-03\",\n",
    "    \"2015-05-01\", \"2015-12-25\", \"2015-12-26\",\n",
    "    \"2016-01-01\", \"2016-03-24\", \"2016-03-25\",\n",
    "    \"2016-07-07\", \"2016-07-18\", \"2016-08-14\",\n",
    "    \"2016-08-15\", \"2016-12-17\", \"2016-12-25\",\n",
    "    \"2016-12-26\", \"2017-01-01\", \"2017-04-14\",\n",
    "    \"2017-05-01\", \"2017-07-04\", \"2017-10-23\",\n",
    "    \"2017-10-31\", \"2017-12-25\", \"2017-12-26\",\n",
    "    \"2018-01-01\", \"2018-03-30\", \"2018-05-01\",\n",
    "    \"2018-05-21\"\n",
    "])\n",
    "\n",
    "# garantir datetime\n",
    "df_inputated[\"Datum\"] = pd.to_datetime(df_inputated[\"Datum\"])\n",
    "\n",
    "# manter apenas datas únicas\n",
    "unique_dates = df_inputated[\"Datum\"].drop_duplicates()\n",
    "\n",
    "# função de expansão\n",
    "def expand(row):\n",
    "    date = row[\"Datum\"]\n",
    "    if date in warengruppe6_dates:\n",
    "        groups = range(1, 7)   # 1..6\n",
    "    else:\n",
    "        groups = range(1, 6)   # 1..5\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Datum\": [date] * len(groups),\n",
    "        \"Warengruppe\": groups\n",
    "    })\n",
    "\n",
    "# aplica expansão\n",
    "expanded = pd.concat(\n",
    "    unique_dates.to_frame().apply(expand, axis=1).to_list(),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# agora juntar VENDAS\n",
    "# merge com o original para obter Umsatz onde existir\n",
    "expanded = expanded.merge(\n",
    "    df_inputated[[\"Datum\", \"Umsatz\"]],\n",
    "    on=\"Datum\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# preencher vendas faltantes com 0\n",
    "expanded[\"Umsatz\"].fillna(0, inplace=True)\n",
    "\n",
    "# criar id = YYMMDD + Warengruppe\n",
    "expanded[\"id\"] = (\n",
    "    expanded[\"Datum\"].dt.strftime(\"%y%m%d\") +\n",
    "    expanded[\"Warengruppe\"].astype(str)\n",
    ")\n",
    "\n",
    "# esse agora é seu df final\n",
    "df_inputated = expanded.sort_values([\"Datum\", \"Warengruppe\"], ignore_index=True)\n",
    "\n",
    "df_inputated.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d6041",
   "metadata": {},
   "source": [
    "Save to csv// import from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6332ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save inputated dataframe to a new CSV file\n",
    "\n",
    "df_inputated.to_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/inputated_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputated = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/inputated_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6dfb5",
   "metadata": {},
   "source": [
    "5. Feature engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e13d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured = df_inputated.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666e088",
   "metadata": {},
   "source": [
    "insert day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1181503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Wochentag\n",
      "0  2013-07-01          1\n",
      "1  2013-07-02          2\n",
      "2  2013-07-03          3\n",
      "3  2013-07-04          4\n",
      "4  2013-07-05          5\n"
     ]
    }
   ],
   "source": [
    "#insert new column day of week as integer (1=Monday,...,7=Sunday)   \n",
    "df_featured['Wochentag'] = pd.to_datetime(df_featured['Datum']).dt.dayofweek + 1\n",
    "print(df_featured[['Datum', 'Wochentag']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b7879",
   "metadata": {},
   "source": [
    "insert holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdaa9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Feiertag\n",
      "0  2013-07-01         0\n",
      "1  2013-07-02         0\n",
      "2  2013-07-03         0\n",
      "3  2013-07-04         0\n",
      "4  2013-07-05         0\n"
     ]
    }
   ],
   "source": [
    "#insert new column holiday from 2013-07-01 to 2018-07-31 \n",
    "holidays = [\n",
    "    '2013-10-03', '2013-12-25', '2013-12-26',\n",
    "    '2014-01-01', '2014-04-18', '2014-04-21',\n",
    "    '2014-05-01', '2014-05-29', '2014-06-09',\n",
    "    '2014-10-03', '2014-12-25', '2014-12-26',\n",
    "    '2015-01-01', '2015-04-03', '2015-04-06',\n",
    "    '2015-05-01', '2015-05-14', '2015-05-25',\n",
    "    '2015-10-03', '2015-12-25', '2015-12-26',\n",
    "    '2016-01-01', '2016-03-25', '2016-03-28',\n",
    "    '2016-05-01', '2016-05-05', '2016-05-16',\n",
    "    '2016-10-03', '2016-12-25', '2016-12-26',\n",
    "    '2017-01-01', '2017-04-14', '2017-04-17',\n",
    "    '2017-05-01', '2017-05-25', '2017-06-05',\n",
    "    '2017-10-03', '2017-10-31', '2017-12-25', '2017-12-26',\n",
    "    '2018-01-01', '2018-03-30', '2018-04-02',\n",
    "    '2018-05-01', '2018-05-10', '2018-05-21'\n",
    "]\n",
    "df_featured['Feiertag'] = df_featured['Datum'].isin(holidays)\n",
    "#convert boolean to integer (0 not holiday, 1 holiday)\n",
    "df_featured['Feiertag'] = df_featured['Feiertag'].astype(int)\n",
    "\n",
    "print(df_featured[['Datum', 'Feiertag']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e7ee8c",
   "metadata": {},
   "source": [
    "set season from day and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cca8111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Monat  Jahreszeit\n",
      "0  2013-07-01      7           3\n",
      "1  2013-07-02      7           3\n",
      "2  2013-07-03      7           3\n",
      "3  2013-07-04      7           3\n",
      "4  2013-07-05      7           3\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# create column season like this: Winter from 22 December to 20 march, Spring from 21 March to 21 june, Summer from 22 June to 21 september, Autumn from 22 September to 21 december\n",
    "def get_season(date_or_month):\n",
    "    # If a date-like is passed (string/Timestamp/date), use exact day-month boundaries\n",
    "    if isinstance(date_or_month, (str, pd.Timestamp, datetime.date)):\n",
    "        d = pd.to_datetime(date_or_month)\n",
    "        m, day = d.month, d.day\n",
    "        if (m == 12 and day >= 22) or m in (1, 2) or (m == 3 and day <= 20):\n",
    "            return 1 #'Winter'\n",
    "        if (m == 3 and day >= 21) or m in (4, 5) or (m == 6 and day <= 21):\n",
    "            return 2 #'Spring'\n",
    "        if (m == 6 and day >= 22) or m in (7, 8) or (m == 9 and day <= 21):\n",
    "            return 3 #'Summer'\n",
    "        return 4 #'Autumn'\n",
    "    # If an integer month is passed, fall back to month-based mapping\n",
    "    m = int(date_or_month)\n",
    "    if m in (12, 1, 2):\n",
    "        return 1 #'Winter'\n",
    "    if m in (3, 4, 5):\n",
    "        return 2 #'Spring'\n",
    "    if m in (6, 7, 8):\n",
    "        return 3 #'Summer'\n",
    "    return 4 #'Autumn'\n",
    "\n",
    "df_featured['Monat'] = pd.to_datetime(df_featured['Datum']).dt.month\n",
    "# Derive season based on the full date (day-month boundaries are respected)\n",
    "df_featured['Jahreszeit'] = pd.to_datetime(df_featured['Datum']).apply(get_season)\n",
    "print(df_featured[['Datum', 'Monat', 'Jahreszeit']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893db3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b7c98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert new column for school holidays (ferien)\n",
    "school_holidays = [\n",
    "    # Summer holidays\n",
    "    ('2013-07-22', '2013-08-31'),\n",
    "    ('2014-07-21', '2014-08-31'),\n",
    "    ('2015-07-20', '2015-08-31'),\n",
    "    ('2016-07-18', '2016-08-31'),\n",
    "    ('2017-07-17', '2017-08-31'),\n",
    "    ('2018-07-16', '2018-08-31'),\n",
    "    # Autumn holidays\n",
    "    ('2013-10-14', '2013-10-26'),\n",
    "    ('2014-10-13', '2014-10-25'),\n",
    "    ('2015-10-12', '2015-10-24'),\n",
    "    ('2016-10-10', '2016-10-22'),\n",
    "    ('2017-10-09', '2017-10-21'),\n",
    "    ('2018-10-08', '2018-10-20'),\n",
    "    # Christmas holidays\n",
    "    ('2013-12-23', '2014-01-05'),\n",
    "    ('2014-12-22', '2015-01-04'),\n",
    "    ('2015-12-21', '2016-01-03'),\n",
    "    ('2016-12-23', '2017-01-06'),\n",
    "    ('2017-12-22', '2018-01-05'),\n",
    "    # Winter holidays\n",
    "    ('2014-02-03', '2014-02-15'),\n",
    "    ('2015-02-02', '2015-02-14'),\n",
    "    ('2016-02-01', '2016-02-13'),\n",
    "    ('2017-01-30', '2017-02-11'),\n",
    "    ('2018-01-29', '2018-02-10'),\n",
    "    # Easter holidays\n",
    "    ('2013-03-25', '2013-04-06'),\n",
    "    ('2014-04-14', '2014-04-25'),\n",
    "    ('2015-04-06', '2015-04-18'),\n",
    "    ('2016-03-21', '2016-04-01'),\n",
    "    ('2017-04-10', '2017-04-21'),\n",
    "    ('2018-03-26', '2018-04-06'),\n",
    "    # Spring holidays\n",
    "    ('2013-05-20', '2013-05-31'),\n",
    "    ('2014-05-19', '2014-05-30'),\n",
    "    ('2015-05-18', '2015-05-29'),\n",
    "    ('2016-05-16', '2016-05-27'),\n",
    "    ('2017-05-15', '2017-05-26'),\n",
    "    ('2018-05-14', '2018-05-25'),\n",
    "]       \n",
    "df_featured['Ferien'] = 0\n",
    "for start, end in school_holidays:\n",
    "    mask = (pd.to_datetime(df_featured['Datum']) >= pd.to_datetime(start)) & (pd.to_datetime(df_featured['Datum']) <= pd.to_datetime(end))\n",
    "    df_featured.loc[mask, 'Ferien'] = 1     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19fa4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save featured dataframe to a new CSV file\n",
    "df_featured.to_csv(r'C:\\Users\\giuli\\Documents\\Open_Campus\\bakery_prediction\\0_DataPreparation\\Processed\\featured_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
