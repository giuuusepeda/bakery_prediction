{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde83e1f",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbae61",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Load cvs files\n",
    "2. Merge files\n",
    "3. correct data types\n",
    "4. inputate NA\n",
    "5. Feature engeneering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4c29e",
   "metadata": {},
   "source": [
    "to do \n",
    "needed another type of join bc the other data will be used for test data \n",
    "apply one hot encoding - to weekday(maybe change to 01 weekend?), new weathercode....\n",
    "moving average for sales, temperature(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008437c",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f63be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad0f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
      "Collecting datetime\n",
      "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting zope.interface (from datetime)\n",
      "  Downloading zope_interface-8.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (45 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
      "Downloading zope_interface-8.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
      "Installing collected packages: zope.interface, datetime\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [datetime]rface]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datetime-5.5 zope.interface-8.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2119937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d237e1",
   "metadata": {},
   "source": [
    "1. Load cvs files"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "6bb431f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\giuli\\\\Documents\\\\Open_Campus\\\\bakery_prediction\\\\0_DataPreparation\\\\Raw\\\\kiwo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load a CSV files\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_kiwo = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiuli\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOpen_Campus\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mbakery_prediction\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m0_DataPreparation\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mRaw\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mkiwo.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_daten = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mgiuli\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mOpen_Campus\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbakery_prediction\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m0_DataPreparation\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mRaw\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mumsatzdaten_gekuerzt.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m df_wetter = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mgiuli\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mOpen_Campus\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbakery_prediction\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m0_DataPreparation\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mRaw\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mwetter.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\giuli\\\\Documents\\\\Open_Campus\\\\bakery_prediction\\\\0_DataPreparation\\\\Raw\\\\kiwo.csv'"
     ]
    }
   ],
   "source": [
    "# Load a CSV files\n",
    "df_kiwo = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/kiwo.csv')\n",
    "df_daten = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/umsatzdaten_gekuerzt.csv')\n",
    "df_wetter = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Raw/wetter.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c865fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the date formats\n",
    "df_kiwo['Datum'] = pd.to_datetime(df_kiwo['Datum'], format='%Y-%m-%d')\n",
    "df_daten['Datum'] = pd.to_datetime(df_daten['Datum'], format='%Y-%m-%d')\n",
    "df_wetter['Datum'] = pd.to_datetime(df_wetter['Datum'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d826aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kiwo antes: Datum\n",
      "2012    9\n",
      "2013    9\n",
      "2014    9\n",
      "2015    9\n",
      "2016    9\n",
      "2017    9\n",
      "2018    9\n",
      "2019    9\n",
      "Name: count, dtype: int64\n",
      "wetter antes: Datum\n",
      "2012    333\n",
      "2013    245\n",
      "2014    365\n",
      "2015    365\n",
      "2016    365\n",
      "2017    363\n",
      "2018    353\n",
      "2019    212\n",
      "Name: count, dtype: int64\n",
      "daten antes: Datum\n",
      "2013     953\n",
      "2014    1824\n",
      "2015    1848\n",
      "2016    1828\n",
      "2017    1841\n",
      "2018    1040\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def year_counts(s):\n",
    "    # conta anos ignorando não-datas\n",
    "    x = pd.to_datetime(s, errors='coerce')\n",
    "    return x.dt.year.value_counts(dropna=True).sort_index()\n",
    "\n",
    "print(\"kiwo antes:\", year_counts(df_kiwo['Datum']))\n",
    "print(\"wetter antes:\", year_counts(df_wetter['Datum']))\n",
    "print(\"daten antes:\", year_counts(df_daten['Datum']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05478783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kiwo ∩ wetter: 2012    9\n",
      "2013    9\n",
      "2014    9\n",
      "2015    9\n",
      "2016    9\n",
      "2017    9\n",
      "2018    9\n",
      "2019    9\n",
      "Name: count, dtype: int64\n",
      "kiwo ∩ daten : 2014    9\n",
      "2015    9\n",
      "2016    9\n",
      "2017    9\n",
      "2018    9\n",
      "Name: count, dtype: int64\n",
      "wetter ∩ daten: 2013    181\n",
      "2014    357\n",
      "2015    360\n",
      "2016    355\n",
      "2017    355\n",
      "2018    208\n",
      "Name: count, dtype: int64\n",
      "kiwo ∩ wetter ∩ daten por ano: 2014    9\n",
      "2015    9\n",
      "2016    9\n",
      "2017    9\n",
      "2018    9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def overlap_by_year(a, b):\n",
    "    inter = pd.Index(a.dropna().unique()).intersection(pd.Index(b.dropna().unique()))\n",
    "    return pd.Series(inter).dt.year.value_counts().sort_index()\n",
    "\n",
    "print(\"kiwo ∩ wetter:\", overlap_by_year(df_kiwo['Datum'], df_wetter['Datum']))\n",
    "print(\"kiwo ∩ daten :\", overlap_by_year(df_kiwo['Datum'], df_daten['Datum']))\n",
    "print(\"wetter ∩ daten:\", overlap_by_year(df_wetter['Datum'], df_daten['Datum']))\n",
    "\n",
    "# interseção tripla\n",
    "tri = (pd.Index(df_kiwo['Datum'].dropna().unique())\n",
    "       .intersection(pd.Index(df_wetter['Datum'].dropna().unique()))\n",
    "       .intersection(pd.Index(df_daten['Datum'].dropna().unique())))\n",
    "print(\"kiwo ∩ wetter ∩ daten por ano:\", pd.Series(tri).dt.year.value_counts().sort_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd213d",
   "metadata": {},
   "source": [
    "2. Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367865f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes on a common column\n",
    "df_kiwowetter = pd.merge(df_daten, df_kiwo, on='Datum', how='outer')\n",
    "\n",
    "df_merged = pd.merge(df_kiwowetter, df_wetter, on='Datum', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02de809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      Datum  Warengruppe  Umsatz  KielerWoche  Bewoelkung  Temperatur  \\\n",
      "0 NaN 2012-01-01          NaN     NaN          NaN         8.0      9.8250   \n",
      "1 NaN 2012-01-02          NaN     NaN          NaN         7.0      7.4375   \n",
      "2 NaN 2012-01-03          NaN     NaN          NaN         8.0      5.5375   \n",
      "3 NaN 2012-01-04          NaN     NaN          NaN         4.0      5.6875   \n",
      "4 NaN 2012-01-05          NaN     NaN          NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode  \n",
      "0                 14.0        58.0  \n",
      "1                 12.0         NaN  \n",
      "2                 18.0        63.0  \n",
      "3                 19.0        80.0  \n",
      "4                 23.0        80.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8a26ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data range in merged dataframe: 2012-01-01 00:00:00 to 2019-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#max and min datum \n",
    "print(\"Data range in merged dataframe:\", df_merged['Datum'].min(), \"to\", df_merged['Datum'].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd65af",
   "metadata": {},
   "source": [
    "3. correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e071f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id  Warengruppe       Umsatz  KielerWoche    Bewoelkung  \\\n",
      "count  9.334000e+03  9334.000000  9334.000000        250.0  10048.000000   \n",
      "mean   1.559311e+06     3.088172   206.749044          1.0      4.748507   \n",
      "std    1.512503e+05     1.489002   144.545189          0.0      2.628285   \n",
      "min    1.307011e+06     1.000000     7.051201          1.0      0.000000   \n",
      "25%    1.410123e+06     2.000000    96.897441          1.0      3.000000   \n",
      "50%    1.601102e+06     3.000000   161.900831          1.0      6.000000   \n",
      "75%    1.704223e+06     4.000000   280.644663          1.0      7.000000   \n",
      "max    1.807315e+06     6.000000  1879.461831          1.0      8.000000   \n",
      "\n",
      "         Temperatur  Windgeschwindigkeit   Wettercode  \n",
      "count  10103.000000         10103.000000  7581.000000  \n",
      "mean      12.014560            11.026527    37.072022  \n",
      "std        7.212466             4.131774    27.207627  \n",
      "min      -10.250000             3.000000     0.000000  \n",
      "25%        6.250000             8.000000    10.000000  \n",
      "50%       11.625000            10.000000    28.000000  \n",
      "75%       17.875000            13.000000    61.000000  \n",
      "max       32.671428            35.000000    95.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10119 entries, 0 to 10118\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   9334 non-null   float64\n",
      " 1   Datum                10119 non-null  object \n",
      " 2   Warengruppe          9334 non-null   float64\n",
      " 3   Umsatz               9334 non-null   float64\n",
      " 4   KielerWoche          250 non-null    float64\n",
      " 5   Bewoelkung           10048 non-null  float64\n",
      " 6   Temperatur           10103 non-null  float64\n",
      " 7   Windgeschwindigkeit  10103 non-null  float64\n",
      " 8   Wettercode           7581 non-null   float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 711.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#descriptive statistics\n",
    "print(df_merged.describe())\n",
    "\n",
    "#data types and non-null counts\n",
    "print(df_merged.info())\n",
    "\n",
    "#missing values in each column\n",
    "#print(df_merged.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8372ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 'Datum' column to datetime\n",
    "df_merged['Datum'] = pd.to_datetime(df_merged['Datum'], errors='coerce').dt.normalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7c86191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set warengruppe, bewoelkung, windgeschwindigkeit, wetter code and kieler woche as integer\n",
    "df_merged['Warengruppe'] = df_merged['Warengruppe'].astype('Int64')\n",
    "df_merged['Windgeschwindigkeit'] = df_merged['Windgeschwindigkeit'].astype('Int64')\n",
    "df_merged['Wettercode'] = df_merged['Wettercode'].astype('Int64')\n",
    "df_merged['KielerWoche'] = df_merged['KielerWoche'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df67459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check if the key datum + warengruppe is unique\n",
    "print(df_merged.duplicated(subset=['Datum', 'Warengruppe']).sum()) #should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d6f17",
   "metadata": {},
   "source": [
    "Save to csv// import from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c1659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save merged dataframe to a new CSV file\n",
    "df_merged.to_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/mergedouter_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a969ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('/workspaces/bakery_prediction/0_DataPreparation/Processed/mergedouter_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b44f4",
   "metadata": {},
   "source": [
    "4. inputate NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30139aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputated = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b40472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                      785\n",
      "Datum                     0\n",
      "Warengruppe             785\n",
      "Umsatz                  785\n",
      "KielerWoche            9869\n",
      "Bewoelkung               71\n",
      "Temperatur               16\n",
      "Windgeschwindigkeit      16\n",
      "Wettercode             2538\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#missing values in each column\n",
    "print(df_inputated.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db25c7",
   "metadata": {},
   "source": [
    "Categorical Wettercode per week mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "669baa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive week and month for df_inputated\n",
    "df_inputated['Woche'] = pd.to_datetime(df_inputated['Datum']).dt.isocalendar().week\n",
    "df_inputated['Monat'] = pd.to_datetime(df_inputated['Datum']).dt.month\n",
    "\n",
    "# precompute weekly and monthly modes (ignore NaNs when computing mode)\n",
    "weekly_mode_map = df_inputated.groupby('Woche')['Wettercode'].agg(\n",
    "    lambda s: s.dropna().mode().iloc[0] if not s.dropna().mode().empty else pd.NA\n",
    ").to_dict()\n",
    "\n",
    "monthly_mode_map = df_inputated.groupby('Monat')['Wettercode'].agg(\n",
    "    lambda s: s.dropna().mode().iloc[0] if not s.dropna().mode().empty else pd.NA\n",
    ").to_dict()\n",
    "\n",
    "# fill missing Wettercode: use weekly mode, if not available fallback to monthly mode\n",
    "def fill_wettercode_row(row):\n",
    "    if pd.isna(row['Wettercode']):\n",
    "        w_mode = weekly_mode_map.get(row['Woche'], pd.NA)\n",
    "        if not pd.isna(w_mode):\n",
    "            return w_mode\n",
    "        return monthly_mode_map.get(row['Monat'], pd.NA)\n",
    "    return row['Wettercode']\n",
    "\n",
    "df_inputated['Wettercode'] = df_inputated.apply(fill_wettercode_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67940ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTES: KielerWoche\n",
      "NaN    9111\n",
      "1.0     223\n",
      "Name: count, dtype: int64\n",
      "DEPOIS: KielerWoche\n",
      "0    9111\n",
      "1     223\n",
      "Name: count, dtype: int64\n",
      "Flips: 0\n",
      "Empty DataFrame\n",
      "Columns: [Datum, KW_before]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['KielerWoche']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Compare antes vs depois\n",
    "print(\"ANTES:\", df_merged['KielerWoche'].value_counts(dropna=False))\n",
    "print(\"DEPOIS:\", df_inputated['KielerWoche'].value_counts(dropna=False))\n",
    "\n",
    "# 2) Quais linhas viraram 0?\n",
    "flip = (df_merged['KielerWoche'] == 1) & (df_inputated['KielerWoche'] == 0)\n",
    "print(\"Flips:\", flip.sum())\n",
    "print(df_merged.loc[flip, ['Datum']].assign(KW_before=1).head())\n",
    "\n",
    "# 3) Veja se há múltiplas colunas de KielerWoche após os merges\n",
    "[k for k in df_merged.columns if 'KielerWoche' in k]\n",
    "[k for k in df_inputated.columns if 'KielerWoche' in k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25ed30",
   "metadata": {},
   "source": [
    "set not kiwo to 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc0504ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_26796\\3859340180.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_inputated['KielerWoche'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#fix kieler woche missing values by filling with 0\n",
    "df_inputated['KielerWoche'].fillna(0, inplace=True)\n",
    "\n",
    "#set 'KielerWoche' as integer (nullable int64 to allow current NaNs)\n",
    "df_inputated['KielerWoche'] = df_inputated['KielerWoche'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fae48",
   "metadata": {},
   "source": [
    "missing Bewoelkung, Temperatur and/or Windgeschwindigkeit\n",
    "Inputated with mean of day after and before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9fe93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datum  Bewoelkung  Temperatur  Windgeschwindigkeit\n",
      "1236  2016-12-11         NaN         NaN                  NaN\n",
      "1526  2017-10-04         NaN         NaN                  NaN\n",
      "1527  2017-10-05         NaN         NaN                  NaN\n",
      "1551  2017-10-30         NaN      8.1000                 11.0\n",
      "1552  2017-11-01         NaN     12.9750                 12.0\n",
      "...          ...         ...         ...                  ...\n",
      "9282  2017-11-04         NaN     10.2625                  5.0\n",
      "9283  2017-11-05         NaN      9.8000                  8.0\n",
      "9284  2017-11-06         NaN      8.2125                  7.0\n",
      "9285  2017-11-07         NaN      6.7875                  5.0\n",
      "9286  2017-11-08         NaN      8.6250                  9.0\n",
      "\n",
      "[70 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#what days are missing Bewoelkung, Temperatur and/or     Windgeschwindigkeit\n",
    "missing_weather = df_inputated[df_inputated[['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']].isnull().any(axis=1)]\n",
    "print(missing_weather[['Datum', 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e8a21",
   "metadata": {},
   "source": [
    "fill Bewoelkung, Temperatur, Windgeschwindigkeit to mean of day before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a009e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing weather data with the mean of day before and after\n",
    "df_inputated['Bewoelkung'] = df_inputated['Bewoelkung'].interpolate()\n",
    "df_inputated['Temperatur'] = df_inputated['Temperatur'].interpolate()\n",
    "df_inputated['Windgeschwindigkeit'] = df_inputated['Windgeschwindigkeit'].interpolate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a0c7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set warengruppe, bewoelkung, windgeschwindigkeit, wetter code and kieler woche as integer\n",
    "df_inputated['Bewoelkung'] = df_inputated['Bewoelkung'].astype('int64')\n",
    "df_inputated['Windgeschwindigkeit'] = df_inputated['Windgeschwindigkeit'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32138d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bewoelkung before imputation: 4.9167725540025415\n",
      "Mean Bewoelkung after imputation: 4.864963503649635\n",
      "Mean Temperatur before imputation: 12.191302867936118\n",
      "Mean Temperatur after imputation: 12.192277110097322\n",
      "Mean Windgeschwindigkeit before imputation: 10.947174447174447\n",
      "Mean Windgeschwindigkeit after imputation: 10.981751824817518\n"
     ]
    }
   ],
   "source": [
    "#median values before and after imputation from 2016-12-11 to 2017-11-08\n",
    "#filter date range\n",
    "df_merged = df_merged[(df_merged['Datum'] >= '2016-12-11') & (df_merged['Datum'] <= '2017-11-08')]\n",
    "df_inputated = df_inputated[(df_inputated['Datum'] >= '2016-12-11') & (df_inputated['Datum'] <= '2017-11-08')]  \n",
    "print(\"Mean Bewoelkung before imputation:\", df_merged['Bewoelkung'].mean())\n",
    "print(\"Mean Bewoelkung after imputation:\", df_inputated['Bewoelkung'].mean())\n",
    "print(\"Mean Temperatur before imputation:\", df_merged['Temperatur'].mean())\n",
    "print(\"Mean Temperatur after imputation:\", df_inputated['Temperatur'].mean())\n",
    "print(\"Mean Windgeschwindigkeit before imputation:\", df_merged['Windgeschwindigkeit'].mean())\n",
    "print(\"Mean Windgeschwindigkeit after imputation:\", df_inputated['Windgeschwindigkeit'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d6d0a",
   "metadata": {},
   "source": [
    "Discrepancies of Bewoelkung, Temperatur and/or     Windgeschwindigkeit for the same day across WarenGruppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a87d7c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies in weather data for the same date:\n",
      "           Datum  Bewoelkung  Temperatur  Windgeschwindigkeit\n",
      "1551  2017-10-30           2           1                    1\n",
      "1552  2017-11-01           2           1                    1\n",
      "1553  2017-11-02           2           1                    1\n",
      "1554  2017-11-03           2           1                    1\n",
      "1555  2017-11-04           2           1                    1\n",
      "1556  2017-11-05           2           1                    1\n",
      "1557  2017-11-06           2           1                    1\n",
      "1558  2017-11-07           2           1                    1\n",
      "1559  2017-11-08           2           1                    1\n"
     ]
    }
   ],
   "source": [
    "# check if there are discrepancies for the same date for the columns 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit'\n",
    "#for 'Warengruppe' 6 the temperature is different for the same date as the other 'Warengruppe'\n",
    "discrepancies = df_inputated.groupby('Datum').agg({\n",
    "    'Bewoelkung': pd.Series.nunique,\n",
    "    'Temperatur': pd.Series.nunique,\n",
    "    'Windgeschwindigkeit': pd.Series.nunique\n",
    "}).reset_index() \n",
    "discrepancies = discrepancies[(discrepancies['Bewoelkung'] > 1) | (discrepancies['Temperatur'] > 1) | (discrepancies['Windgeschwindigkeit'] > 1)]\n",
    "print(\"Discrepancies in weather data for the same date:\")\n",
    "print(discrepancies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438c599",
   "metadata": {},
   "source": [
    "uses value of WarenGruppe 1 to all groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c7e8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Bewoelkung', 'Temperatur', 'Windgeschwindigkeit']\n",
    "\n",
    "for date in discrepancies['Datum']:\n",
    "    weather_values = df_inputated.loc[df_inputated['Datum'] == date, ['Warengruppe'] + cols]\n",
    "    reference_values = weather_values.loc[weather_values['Warengruppe'] == 1, cols].iloc[0]\n",
    "    # >>> use .values para evitar alinhamento por rótulo <<<\n",
    "    df_inputated.loc[df_inputated['Datum'] == date, cols] = reference_values.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d6041",
   "metadata": {},
   "source": [
    "Save to csv// import from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save inputated dataframe to a new CSV file\n",
    "\n",
    "#df_inputated.to_csv(r'C:\\Users\\giuli\\Documents\\Open_Campus\\bakery_prediction\\0_DataPreparation\\Processed\\inputated_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b55f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputated = pd.read_csv(r'C:\\Users\\giuli\\Documents\\Open_Campus\\bakery_prediction\\0_DataPreparation\\Processed\\inputated_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6dfb5",
   "metadata": {},
   "source": [
    "5. Feature engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e13d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featured = df_inputated.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666e088",
   "metadata": {},
   "source": [
    "insert day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1181503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Wochentag\n",
      "0  2013-07-01          1\n",
      "1  2013-07-02          2\n",
      "2  2013-07-03          3\n",
      "3  2013-07-04          4\n",
      "4  2013-07-05          5\n"
     ]
    }
   ],
   "source": [
    "#insert new column day of week as integer (1=Monday,...,7=Sunday)   \n",
    "df_featured['Wochentag'] = pd.to_datetime(df_featured['Datum']).dt.dayofweek + 1\n",
    "print(df_featured[['Datum', 'Wochentag']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b7879",
   "metadata": {},
   "source": [
    "insert holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdaa9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Feiertag\n",
      "0  2013-07-01         0\n",
      "1  2013-07-02         0\n",
      "2  2013-07-03         0\n",
      "3  2013-07-04         0\n",
      "4  2013-07-05         0\n"
     ]
    }
   ],
   "source": [
    "#insert new column holiday from 2013-07-01 to 2018-07-31 \n",
    "holidays = [\n",
    "    '2013-10-03', '2013-12-25', '2013-12-26',\n",
    "    '2014-01-01', '2014-04-18', '2014-04-21',\n",
    "    '2014-05-01', '2014-05-29', '2014-06-09',\n",
    "    '2014-10-03', '2014-12-25', '2014-12-26',\n",
    "    '2015-01-01', '2015-04-03', '2015-04-06',\n",
    "    '2015-05-01', '2015-05-14', '2015-05-25',\n",
    "    '2015-10-03', '2015-12-25', '2015-12-26',\n",
    "    '2016-01-01', '2016-03-25', '2016-03-28',\n",
    "    '2016-05-01', '2016-05-05', '2016-05-16',\n",
    "    '2016-10-03', '2016-12-25', '2016-12-26',\n",
    "    '2017-01-01', '2017-04-14', '2017-04-17',\n",
    "    '2017-05-01', '2017-05-25', '2017-06-05',\n",
    "    '2017-10-03', '2017-10-31', '2017-12-25', '2017-12-26',\n",
    "    '2018-01-01', '2018-03-30', '2018-04-02',\n",
    "    '2018-05-01', '2018-05-10', '2018-05-21'\n",
    "]\n",
    "df_featured['Feiertag'] = df_featured['Datum'].isin(holidays)\n",
    "#convert boolean to integer (0 not holiday, 1 holiday)\n",
    "df_featured['Feiertag'] = df_featured['Feiertag'].astype(int)\n",
    "\n",
    "print(df_featured[['Datum', 'Feiertag']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e7ee8c",
   "metadata": {},
   "source": [
    "set season from day and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cca8111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Monat  Jahreszeit\n",
      "0  2013-07-01      7           3\n",
      "1  2013-07-02      7           3\n",
      "2  2013-07-03      7           3\n",
      "3  2013-07-04      7           3\n",
      "4  2013-07-05      7           3\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# create column season like this: Winter from 22 December to 20 march, Spring from 21 March to 21 june, Summer from 22 June to 21 september, Autumn from 22 September to 21 december\n",
    "def get_season(date_or_month):\n",
    "    # If a date-like is passed (string/Timestamp/date), use exact day-month boundaries\n",
    "    if isinstance(date_or_month, (str, pd.Timestamp, datetime.date)):\n",
    "        d = pd.to_datetime(date_or_month)\n",
    "        m, day = d.month, d.day\n",
    "        if (m == 12 and day >= 22) or m in (1, 2) or (m == 3 and day <= 20):\n",
    "            return 1 #'Winter'\n",
    "        if (m == 3 and day >= 21) or m in (4, 5) or (m == 6 and day <= 21):\n",
    "            return 2 #'Spring'\n",
    "        if (m == 6 and day >= 22) or m in (7, 8) or (m == 9 and day <= 21):\n",
    "            return 3 #'Summer'\n",
    "        return 4 #'Autumn'\n",
    "    # If an integer month is passed, fall back to month-based mapping\n",
    "    m = int(date_or_month)\n",
    "    if m in (12, 1, 2):\n",
    "        return 1 #'Winter'\n",
    "    if m in (3, 4, 5):\n",
    "        return 2 #'Spring'\n",
    "    if m in (6, 7, 8):\n",
    "        return 3 #'Summer'\n",
    "    return 4 #'Autumn'\n",
    "\n",
    "df_featured['Monat'] = pd.to_datetime(df_featured['Datum']).dt.month\n",
    "# Derive season based on the full date (day-month boundaries are respected)\n",
    "df_featured['Jahreszeit'] = pd.to_datetime(df_featured['Datum']).apply(get_season)\n",
    "print(df_featured[['Datum', 'Monat', 'Jahreszeit']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893db3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b7c98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert new column for school holidays (ferien)\n",
    "school_holidays = [\n",
    "    # Summer holidays\n",
    "    ('2013-07-22', '2013-08-31'),\n",
    "    ('2014-07-21', '2014-08-31'),\n",
    "    ('2015-07-20', '2015-08-31'),\n",
    "    ('2016-07-18', '2016-08-31'),\n",
    "    ('2017-07-17', '2017-08-31'),\n",
    "    ('2018-07-16', '2018-08-31'),\n",
    "    # Autumn holidays\n",
    "    ('2013-10-14', '2013-10-26'),\n",
    "    ('2014-10-13', '2014-10-25'),\n",
    "    ('2015-10-12', '2015-10-24'),\n",
    "    ('2016-10-10', '2016-10-22'),\n",
    "    ('2017-10-09', '2017-10-21'),\n",
    "    ('2018-10-08', '2018-10-20'),\n",
    "    # Christmas holidays\n",
    "    ('2013-12-23', '2014-01-05'),\n",
    "    ('2014-12-22', '2015-01-04'),\n",
    "    ('2015-12-21', '2016-01-03'),\n",
    "    ('2016-12-23', '2017-01-06'),\n",
    "    ('2017-12-22', '2018-01-05'),\n",
    "    # Winter holidays\n",
    "    ('2014-02-03', '2014-02-15'),\n",
    "    ('2015-02-02', '2015-02-14'),\n",
    "    ('2016-02-01', '2016-02-13'),\n",
    "    ('2017-01-30', '2017-02-11'),\n",
    "    ('2018-01-29', '2018-02-10'),\n",
    "    # Easter holidays\n",
    "    ('2013-03-25', '2013-04-06'),\n",
    "    ('2014-04-14', '2014-04-25'),\n",
    "    ('2015-04-06', '2015-04-18'),\n",
    "    ('2016-03-21', '2016-04-01'),\n",
    "    ('2017-04-10', '2017-04-21'),\n",
    "    ('2018-03-26', '2018-04-06'),\n",
    "    # Spring holidays\n",
    "    ('2013-05-20', '2013-05-31'),\n",
    "    ('2014-05-19', '2014-05-30'),\n",
    "    ('2015-05-18', '2015-05-29'),\n",
    "    ('2016-05-16', '2016-05-27'),\n",
    "    ('2017-05-15', '2017-05-26'),\n",
    "    ('2018-05-14', '2018-05-25'),\n",
    "]       \n",
    "df_featured['Ferien'] = 0\n",
    "for start, end in school_holidays:\n",
    "    mask = (pd.to_datetime(df_featured['Datum']) >= pd.to_datetime(start)) & (pd.to_datetime(df_featured['Datum']) <= pd.to_datetime(end))\n",
    "    df_featured.loc[mask, 'Ferien'] = 1     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19fa4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save featured dataframe to a new CSV file\n",
    "df_featured.to_csv(r'C:\\Users\\giuli\\Documents\\Open_Campus\\bakery_prediction\\0_DataPreparation\\Processed\\featured_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
<<<<<<< Updated upstream
=======
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
